import pandas as pd
from imblearn.over_sampling  import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, f1_score, recall_score, precision_score, accuracy_score

df = pd.read_csv(r'C:/Users/HP PC/Desktop/credit/creditcard.csv')


print(df.info())


print(" First ten values:\n", df.head(10))
print(" \n Statistical Values of the dataset:\n", df.describe())

print ("\nDataset With missing values from Row 1-10:\n", df.iloc[0:10].isnull())

print(df. isnull().sum())

#Checking the distribution of classes

class_counts= df['Class'].value_counts()

print("\n Class Distribution:\n ", class_counts)


#Seperate features (X) and target variables (y)
#Where class is the target variable


df_sample= df.sample(frac=0.1, random_state= 42)


X= df.drop(columns=['Class']) 
y=df['Class']



#apply smote to balance dataset

smote= SMOTE(random_state=42)


X_resampled, y_resampled=smote.fit_resample(X,y)

print(f'Class distribution after SMOTE:\n{y_resampled.value_counts()}')


X_train, X_test, y_train, y_test= train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)

#Check the shapes of the training and testing sets

print(f"Training  set size: {X_train.shape}, {y_train.shape}")
print(f"Testing set size:{X_test.shape}, {y_test.shape}")

#Train Random Forest Model



model= LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)


#Make predictions on the test set


y_pred = model.predict(X_test)





#Evaluate the model using precision, recall, f1-score, and accuracy

print("Classification Report:")
print(classification_report(y_test, y_pred))


precision= precision_score(y_test, y_pred)
recall= recall_score(y_test, y_pred)
fsc= f1_score(y_test, y_pred)
accuracy= accuracy_score(y_test, y_pred)


print (f"Precision:{precision}")
print (f"Recall:{recall}")
print (f"F1-Score:{fsc}")
print (f"Accuracy:{accuracy}")

print("Number Of Transactions Predicted as Fraudulent:", {sum(y_pred)})




input()
